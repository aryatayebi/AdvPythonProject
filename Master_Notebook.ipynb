{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Cython\n",
    "from Cython.Compiler import Options\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Cython.Compiler.Options.get_directive_defaults()['linetrace'] = True\n",
    "Cython.Compiler.Options.get_directive_defaults()['binding'] = True\n",
    "\n",
    "%reload_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/farrisatif/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOSMIL512022 Boston Celtics Milwaukee Bucks\n",
      "BOSMIL532022 Boston Celtics Milwaukee Bucks\n",
      "MEMGS512022 Memphis Grizzlies Golden State Warriors\n",
      "MEMGS532022 Memphis Grizzlies Golden State Warriors\n",
      "MIAPHI522022 Miami Heat Philadelphia 76ers\n",
      "MIAPHI542022 Miami Heat Philadelphia 76ers\n",
      "PHODAL522022 Phoenix Suns Dallas Mavericks\n",
      "PHODAL542022 Phoenix Suns Dallas Mavericks\n",
      "70.7258129119873 seconds\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "cimport numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import sys\n",
    "import tweepy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import pycountry\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from langdetect import detect\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import pytz\n",
    "import time\n",
    "nltk.download('vader_lexicon')\n",
    "from keys import *\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "client = tweepy.Client(bearer_token=bearer_token,\\\n",
    "                       consumer_key = consumer_key,\\\n",
    "                       consumer_secret = consumer_secret,\\\n",
    "                       access_token = access_token,\\\n",
    "                       access_token_secret = access_token_secret)\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "df_data = pd.read_csv(\"finalNbaData.csv\").drop('Unnamed: 0', axis=1)\n",
    "df_data.dateTime = pd.to_datetime(df_data.dateTime)\n",
    "utc=pytz.UTC\n",
    "weekPriorDate = datetime.datetime.now() - timedelta(days=6)\n",
    "weekPriorDate = utc.localize(weekPriorDate) \n",
    "\n",
    "df_data.dateTime = df_data.dateTime.apply(lambda x: x.replace(tzinfo=None))\n",
    "study_games = df_data[df_data.dateTime > weekPriorDate.replace(tzinfo=None)].__id__.unique()\n",
    "\n",
    "def percentage(double part, double whole):\n",
    "    cdef double prod = 100 * float(part)/float(whole)\n",
    "    return prod \n",
    "\n",
    "def clean_tweets(tweet_list):\n",
    "    tweet_list = [re.sub('RT @\\w+: ',\" \",x) for x in tweet_list]\n",
    "    tweet_list = [re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x) for x in tweet_list]\n",
    "    tweet_list = [x.lower() for x in tweet_list]\n",
    "    return tweet_list\n",
    "\n",
    "\n",
    "def run(game_id):\n",
    "    df = df_data[df_data.__id__ == game_id]\n",
    "    home_team = df['homeTeam'].values[0]\n",
    "    away_team = df['awayTeam'].values[0]\n",
    "\n",
    "    game_datetime = pd.to_datetime(df['dateTime'].values[0])\n",
    "    game_datetime_end = game_datetime\n",
    "    game_datetime_start = game_datetime - timedelta(hours=5, minutes=0)\n",
    "    \n",
    "    \n",
    "    print (game_id, home_team, away_team)\n",
    "    \n",
    "    # home tweets \n",
    "    home_tweet_list = []\n",
    "    cdef int home_negative = 0\n",
    "    cdef int home_positive = 0\n",
    "    cdef int home_neutral = 0\n",
    "    \n",
    "    for tweet in tweepy.Paginator(client.search_recent_tweets, query=home_team,\n",
    "                              tweet_fields=['lang', 'created_at'], max_results=100, start_time=game_datetime_start, end_time=game_datetime_end).flatten(limit=search_limit):\n",
    "\n",
    "        if tweet.lang == 'en':\n",
    "            home_tweet_list.append(tweet.text)\n",
    "     \n",
    "    cdef int home_tweet_count = len(set(home_tweet_list))\n",
    "    \n",
    "    for tweet in clean_tweets(list(set(home_tweet_list))):\n",
    "        score = SentimentIntensityAnalyzer().polarity_scores(tweet)\n",
    "        neg = score['neg']\n",
    "        neu = score['neu']\n",
    "        pos = score['pos']\n",
    "\n",
    "        if neg > pos:\n",
    "            home_negative += 1\n",
    "        elif pos > neg:\n",
    "            home_positive += 1\n",
    "        elif pos == neg:\n",
    "            home_neutral += 1\n",
    "    \n",
    "    # away tweets\n",
    "    away_tweet_list = []\n",
    "    cdef int away_negative = 0\n",
    "    cdef int away_positive = 0\n",
    "    cdef int away_neutral  = 0\n",
    "    \n",
    "    for tweet in tweepy.Paginator(client.search_recent_tweets, query=away_team,\n",
    "                              tweet_fields=['lang', 'created_at'], max_results=100, start_time=game_datetime_start, end_time=game_datetime_end).flatten(limit=search_limit):\n",
    "\n",
    "        if tweet.lang == 'en':\n",
    "            away_tweet_list.append(tweet.text)\n",
    "    \n",
    "    cdef int away_tweet_count = len(set(away_tweet_list))\n",
    "    \n",
    "    for tweet in clean_tweets(list(set(away_tweet_list))):\n",
    "        score = SentimentIntensityAnalyzer().polarity_scores(tweet)\n",
    "        neg = score['neg']\n",
    "        neu = score['neu']\n",
    "        pos = score['pos']\n",
    "\n",
    "        if neg > pos:\n",
    "            away_negative += 1\n",
    "        elif pos > neg:\n",
    "            away_positive += 1\n",
    "        elif pos == neg:\n",
    "            away_neutral += 1\n",
    "    \n",
    "    return pd.DataFrame([[game_id, home_team, away_team, percentage(home_positive, home_tweet_count), percentage(home_negative, home_tweet_count), percentage(home_neutral, home_tweet_count),\n",
    "           percentage(away_positive, away_tweet_count), percentage(away_negative, away_tweet_count), percentage(away_neutral, away_tweet_count), away_tweet_count + home_tweet_count]], \n",
    "           columns=['gameID', 'homeTeam', 'awayTeam','homePositive', 'homeNegative', 'homeNeutral', 'awayPositive', 'awayNegative', 'awayNeutral', 'total_tweets_analyzed'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sentiment_results = []\n",
    "cdef int search_limit = 500\n",
    "for s in study_games:\n",
    "    sentiment_results.append(run(s))\n",
    "end_time = time.time()\n",
    "print(end_time - start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameID</th>\n",
       "      <th>homeTeam</th>\n",
       "      <th>awayTeam</th>\n",
       "      <th>homePositive</th>\n",
       "      <th>homeNegative</th>\n",
       "      <th>homeNeutral</th>\n",
       "      <th>awayPositive</th>\n",
       "      <th>awayNegative</th>\n",
       "      <th>awayNeutral</th>\n",
       "      <th>total_tweets_analyzed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOSMIL512022</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>Milwaukee Bucks</td>\n",
       "      <td>38.565022</td>\n",
       "      <td>6.278027</td>\n",
       "      <td>55.156951</td>\n",
       "      <td>37.198068</td>\n",
       "      <td>2.898551</td>\n",
       "      <td>59.903382</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOSMIL532022</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>Milwaukee Bucks</td>\n",
       "      <td>54.166667</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>55.421687</td>\n",
       "      <td>3.212851</td>\n",
       "      <td>41.365462</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEMGS512022</td>\n",
       "      <td>Memphis Grizzlies</td>\n",
       "      <td>Golden State Warriors</td>\n",
       "      <td>48.214286</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>48.214286</td>\n",
       "      <td>53.080569</td>\n",
       "      <td>1.895735</td>\n",
       "      <td>45.023697</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEMGS532022</td>\n",
       "      <td>Memphis Grizzlies</td>\n",
       "      <td>Golden State Warriors</td>\n",
       "      <td>36.842105</td>\n",
       "      <td>11.004785</td>\n",
       "      <td>52.153110</td>\n",
       "      <td>46.031746</td>\n",
       "      <td>8.730159</td>\n",
       "      <td>45.238095</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIAPHI522022</td>\n",
       "      <td>Miami Heat</td>\n",
       "      <td>Philadelphia 76ers</td>\n",
       "      <td>54.393305</td>\n",
       "      <td>7.949791</td>\n",
       "      <td>37.656904</td>\n",
       "      <td>50.490196</td>\n",
       "      <td>6.862745</td>\n",
       "      <td>42.647059</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIAPHI542022</td>\n",
       "      <td>Miami Heat</td>\n",
       "      <td>Philadelphia 76ers</td>\n",
       "      <td>39.483395</td>\n",
       "      <td>13.653137</td>\n",
       "      <td>46.863469</td>\n",
       "      <td>32.272727</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>52.727273</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHODAL522022</td>\n",
       "      <td>Phoenix Suns</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>42.748092</td>\n",
       "      <td>11.068702</td>\n",
       "      <td>46.183206</td>\n",
       "      <td>56.569343</td>\n",
       "      <td>4.744526</td>\n",
       "      <td>38.686131</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHODAL542022</td>\n",
       "      <td>Phoenix Suns</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>49.765258</td>\n",
       "      <td>9.859155</td>\n",
       "      <td>40.375587</td>\n",
       "      <td>47.027027</td>\n",
       "      <td>7.567568</td>\n",
       "      <td>45.405405</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gameID           homeTeam               awayTeam  homePositive  \\\n",
       "0  BOSMIL512022     Boston Celtics        Milwaukee Bucks     38.565022   \n",
       "0  BOSMIL532022     Boston Celtics        Milwaukee Bucks     54.166667   \n",
       "0   MEMGS512022  Memphis Grizzlies  Golden State Warriors     48.214286   \n",
       "0   MEMGS532022  Memphis Grizzlies  Golden State Warriors     36.842105   \n",
       "0  MIAPHI522022         Miami Heat     Philadelphia 76ers     54.393305   \n",
       "0  MIAPHI542022         Miami Heat     Philadelphia 76ers     39.483395   \n",
       "0  PHODAL522022       Phoenix Suns       Dallas Mavericks     42.748092   \n",
       "0  PHODAL542022       Phoenix Suns       Dallas Mavericks     49.765258   \n",
       "\n",
       "   homeNegative  homeNeutral  awayPositive  awayNegative  awayNeutral  \\\n",
       "0      6.278027    55.156951     37.198068      2.898551    59.903382   \n",
       "0      5.833333    40.000000     55.421687      3.212851    41.365462   \n",
       "0      3.571429    48.214286     53.080569      1.895735    45.023697   \n",
       "0     11.004785    52.153110     46.031746      8.730159    45.238095   \n",
       "0      7.949791    37.656904     50.490196      6.862745    42.647059   \n",
       "0     13.653137    46.863469     32.272727     15.000000    52.727273   \n",
       "0     11.068702    46.183206     56.569343      4.744526    38.686131   \n",
       "0      9.859155    40.375587     47.027027      7.567568    45.405405   \n",
       "\n",
       "   total_tweets_analyzed  \n",
       "0                    430  \n",
       "0                    489  \n",
       "0                    435  \n",
       "0                    461  \n",
       "0                    443  \n",
       "0                    491  \n",
       "0                    536  \n",
       "0                    398  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentiment_results = pd.concat(sentiment_results)\n",
    "sentiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farrisatif/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8095238095238095"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = copy.deepcopy(df_data)\n",
    "ss = copy.deepcopy(sentiment_results)\n",
    "df2 = copy.deepcopy(df)\n",
    "\n",
    "df = df.drop(['sport', 'awayDiff', 'awayOutcome', 'gameState', 'homeDiff', 'sbId', 'score', 'total', '__id__', 'dateTime', 'under'], 1)\n",
    "df = df.rename(columns={'id': 'gameID'})\n",
    "df = df[['gameID', 'homeTeam', 'awayTeam', 'awayOdds', 'awaySpread', 'awaySpreadOdds', 'homeOdds', 'homeSpread', 'homeSpreadOdds', 'over', 'overOdds', 'underOdds', 'homeOutcome']]\n",
    "df['y'] = np.where(df.homeOutcome == 'W', 1, 0)\n",
    "df = df.drop('homeOutcome', 1)\n",
    "df = pd.merge(df, ss, on=['gameID', 'homeTeam', 'awayTeam'], how='left')\n",
    "df = df.drop('total_tweets_analyzed', 1)\n",
    "df = df.fillna(0)\n",
    "df.awayOdds = np.where(df.awayOdds < 0, 1 - (100 / df.awayOdds), 1 + (df.awayOdds / 100))\n",
    "df.homeOdds = np.where(df.homeOdds < 0, 1 - (100 / df.homeOdds), 1 + (df.homeOdds / 100))\n",
    "df.overOdds = np.where(df.overOdds < 0, 1 - (100 / df.overOdds), 1 + (df.overOdds / 100))\n",
    "df.underOdds = np.where(df.underOdds < 0, 1 - (100 / df.underOdds), 1 + (df.underOdds / 100))\n",
    "X = df.iloc[:, 3:].drop('y', 1)\n",
    "y = df.y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = copy.deepcopy(df_data)\n",
    "ss = copy.deepcopy(sentiment_results)\n",
    "\n",
    "df = df.drop(['sport', 'awayDiff', 'awayOutcome', 'gameState', 'homeDiff', 'sbId', 'score', 'total', '__id__', 'dateTime', 'under'], 1)\n",
    "df = df.rename(columns={'id': 'gameID'})\n",
    "df = df[['gameID', 'homeTeam', 'awayTeam', 'awayOdds', 'awaySpread', 'awaySpreadOdds', 'homeOdds', 'homeSpread', 'homeSpreadOdds', 'over', 'overOdds', 'underOdds', 'homeOutcome']]\n",
    "df['y'] = np.where(df.homeOutcome == 'W', 1, 0)\n",
    "df = df.drop('homeOutcome', 1)\n",
    "df = pd.merge(df, ss, on=['gameID', 'homeTeam', 'awayTeam'], how='left')\n",
    "df = df.drop('total_tweets_analyzed', 1)\n",
    "df = df.fillna(0)\n",
    "df = df.drop(['homePositive', 'homeNegative',\n",
    "       'homeNeutral', 'awayPositive', 'awayNegative', 'awayNeutral'], axis=1)\n",
    "df.awayOdds = np.where(df.awayOdds < 0, 1 - (100 / df.awayOdds), 1 + (df.awayOdds / 100))\n",
    "df.homeOdds = np.where(df.homeOdds < 0, 1 - (100 / df.homeOdds), 1 + (df.homeOdds / 100))\n",
    "df.overOdds = np.where(df.overOdds < 0, 1 - (100 / df.overOdds), 1 + (df.overOdds / 100))\n",
    "df.underOdds = np.where(df.underOdds < 0, 1 - (100 / df.underOdds), 1 + (df.underOdds / 100))\n",
    "X = df.iloc[:, 3:].drop('y', 1)\n",
    "y = df.y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
